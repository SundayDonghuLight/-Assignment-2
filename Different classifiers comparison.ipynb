{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.9913666666666666\n",
      "測試資料辨識率: 0.9825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')                                       #載入'MNIST original'手寫字資料集存入變數mnist中\n",
    "\n",
    "index = np.arange(len(mnist.data))                                           #產生與data數相同長度(0~69999)的陣列\n",
    "random.shuffle(index)                                                        #將該陣列隨機洗牌，打亂順序\n",
    "train_index = index[0:60000]                                                 #前60000筆對應的編號作為訓練資料\n",
    "test_index = index[60000:70000]                                              #後10000筆對應的編號則作為測試資料\n",
    "X_train, y_train = mnist.data[train_index], mnist.target[train_index]\n",
    "X_test, y_test = mnist.data[test_index], mnist.target[test_index]\n",
    "\n",
    "pca = PCA(n_components=30)                                                   #使用PCA套件，設定降至30維\n",
    "newX_train = pca.fit_transform(X_train)                                      #用訓練資料配適降階用的半正交矩陣並把轉換後結果存至newX_train\n",
    "newX_test = pca.transform(X_test)                                            #用剛剛找出的矩陣對訓練資料也進行轉換，存入newX_test\n",
    "newX_train = newX_train/255                                                  #將資料進行歸一化(normalization)\n",
    "newX_test = newX_test/255                                                    #這邊除255等同於sklearn的MinMaxScaler\n",
    "\n",
    "clf = SVC()                                                                  #使用SVC(Support Vector Classification)進行辨識\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.9906833333333334\n",
      "測試資料辨識率: 0.9733\n",
      "48.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(60))\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.8808833333333334\n",
      "測試資料辨識率: 0.876\n",
      "13.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='sag', max_iter=1000)\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.8605833333333334\n",
      "測試資料辨識率: 0.8512\n",
      "785 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.8581\n",
      "測試資料辨識率: 0.8568\n",
      "756 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.9846666666666667\n",
      "測試資料辨識率: 0.9774\n",
      "3min 7s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 1.0\n",
      "測試資料辨識率: 0.8482\n",
      "6.78 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.9988333333333334\n",
      "測試資料辨識率: 0.9283\n",
      "6.39 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.7102666666666667\n",
      "測試資料辨識率: 0.7068\n",
      "22.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料辨識率: 0.99725\n",
      "測試資料辨識率: 0.9128\n",
      "37 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier()\n",
    "clf.fit(newX_train, y_train)\n",
    "print(\"訓練資料辨識率:\",np.mean(clf.predict(newX_train) == y_train))\n",
    "print(\"測試資料辨識率:\",np.mean(clf.predict(newX_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
